[
  {"id": 1, "use": true, "param": "loss", "type": "string", "default_value": {"label": "log_loss", "value":  "log_loss"}, "name": "ошибка", "info": "Функция потерь, подлежащая оптимизации. «log_loss» относится к биномиальному и полиномиальному отклонению, такому же, как и в логистической регрессии. Это хороший выбор для классификации с вероятностными результатами. Для «экспоненциальных» потерь повышение градиента восстанавливает алгоритм AdaBoost.", "diap": ["log_loss", "exponential"]},
  {"id": 2, "use": true, "param": "learning_rate", "type": "float", "default_value": 0.01, "name": "скорость обучения", "info": "Скорость обучения уменьшает вклад каждого дерева на значение Learning_rate. Существует компромисс между Learning_rate и n_estimators. Значения должны находиться в диапазоне [0,0, inf).", "diap": [0]},
  {"id": 3, "use": true, "param": "n_estimators", "type": "int", "default_value": 100, "name": "Кол-во оценщиков", "info": "Количество этапов повышения, которые необходимо выполнить. Повышение градиента довольно устойчиво к переобучению, поэтому большое его значение обычно приводит к повышению производительности. Значения должны находиться в диапазоне [1, inf).", "diap": [1]},
  {"id": 4, "use": true, "param": "subsample", "type": "float", "default_value": 1, "name": "подвыборка", "info": "Доля выборок, которая будет использоваться для подбора отдельных базовых учащихся. Если значение меньше 1,0, это приводит к повышению стохастического градиента. подвыборка взаимодействует с параметром n_estimators. Выбор подвыборки < 1,0 приводит к уменьшению дисперсии и увеличению систематической ошибки. Значения должны находиться в диапазоне (0,0, 1,0].", "diap": [0, 1]},
  {"id": 5, "use": true, "param": "criterion", "type": "string", "default_value": {"label": "friedman_mse", "value":  "friedman_mse"}, "name": "Критерий ", "info": "Функция для измерения качества разделения. Поддерживаемые критерии: «friedman_mse» для среднеквадратической ошибки с оценкой улучшения по Фридману, «squared_error» для среднеквадратической ошибки. Значение по умолчанию «friedman_mse», как правило, является лучшим, поскольку в некоторых случаях оно может обеспечить лучшее приближение.", "diap": ["friedman_mse", "squared_error"]},
  {"id": 6, "use": true, "param": "max_depth", "type": "int", "default_value": 3, "name": "Максимальная глубина дерева", "info": "Если None, то узлы расширяются до тех пор, пока все листья не станут чистыми или пока все листья не будут содержать менее min_samples_split выборок.", "diap": [0]},
  {"id": 7, "use": true, "param": "min_samples_split", "type": "float", "default_value": 0.1, "name": "Минимальное разбиение выбоки", "info": "Если число с плавающей запятой, то min_samples_splitэто дробь и минимальное количество выборок для каждого разделения.ceil(min_samples_split * n_samples)", "diap": [0, 1]},
  {"id": 8, "use": true, "param": "min_samples_leaf", "type": "float", "default_value": 0.1, "name": "Минимальное количество выборок, которое должно находиться в листовом узле.", "info": "Точка разделения на любой глубине будет учитываться только в том случае, если она оставляет хотя бы min_samples_leafобучающие выборки в каждой из левой и правой ветвей. Это может привести к сглаживанию модели, особенно в регрессионном режиме. Если int, то считать min_samples_leafминимальным числом. Если с плавающей запятой, то min_samples_leafэто дробь и минимальное количество выборок для каждого узла.ceil(min_samples_leaf * n_samples)", "diap": [0, 1]},
  {"id": 9, "use": true, "param": "min_weight_fraction_leaf", "type": "float", "default_value": 0.0, "name": "Минимальная взвешенная доля суммы весов.", "info": "Минимальная взвешенная доля суммы весов (всех входных выборок), которая должна находиться в листовом узле. Выборки имеют одинаковый вес, если параметр sample_weight не указан.", "diap": [0, 0.5]},
  {"id": 10, "use": true, "param": "max_features", "type": "string", "default_value": "sqrt", "name": "Количество особенностей, которые следует учитывать при поиске лучшего разделения.", "info": "Если «sqrt», то max_features=sqrt(n_features). Если «log2», то max_features=log2(n_features). Если Нет, то max_features=n_features.\n\nПримечание: поиск разделения не прекращается до тех пор, пока не будет найден хотя бы один действительный раздел образцов узлов, даже если для этого требуется эффективно проверить не только max_featuresфункции.", "diap": [null, "sqrt", "log2"]},
  {"id": 11, "use": true, "param": "max_leaf_nodes", "type": "int", "default_value": null, "name": "Оптимизатор роста дерева", "info": "Выращивайте деревья с помощью max_leaf_nodes наилучшим образом. Лучшие узлы определяются как относительное уменьшение примесей. Значения должны находиться в диапазоне [2, инф). Если Нет, то неограниченное количество конечных узлов.", "diap": [2]},
  {"id": 12, "use": true, "param": "min_impurity_decrease", "type": "float", "default_value": 0.0, "name": "минимальное снижение примесей", "info": "Узел будет разделен, если это разделение приведет к уменьшению примеси, превышающему или равное этому значению. Значения должны находиться в диапазоне [0,0, inf).", "diap": [0]},
  {"id": 13, "use": false, "param": "init", "type": "int", "default_value": null, "name": "оценщик", "info": "Объект оценки, используемый для вычисления начальных прогнозов. init должен обеспечить соответствие и Predict_proba. Если «ноль», первоначальные необработанные прогнозы устанавливаются равными нулю. По умолчанию используется DummyEstimator, прогнозирующий априорные значения классов.", "diap": null},
  {"id": 14, "use": true, "param": "verbose", "type": "int", "default_value": 0, "name": "Подробность", "info": "Для решателей liblinear и lbfgs установите для verbose любое положительное число.", "diap": [0]},
  {"id": 15, "use": true, "param": "random_state", "type": "int", "default_value": null, "name": "Управляет случайностью оценки.", "info": "Объекты всегда случайным образом переставляются при каждом разбиении, даже если splitterустановлено значение \"best\". Когда , алгоритм будет выбирать случайным образом для каждого разделения, прежде чем найти среди них лучшее разделение. Но наилучшее найденное разделение может различаться в разных прогонах, даже если . Это тот случай, когда улучшение критерия одинаково для нескольких разбиений и одно разбиение должно быть выбрано случайным образом. Чтобы получить детерминированное поведение во время подгонки, необходимо зафиксировать целое число. .max_features < n_featuresmax_featuresmax_features=n_featuresrandom_state", "diap": [0]},
  {"id": 16, "use": true, "param": "warm_start", "type": "bool", "default_value": false, "name": "Тепловое начало", "info": "Если установлено значение True, повторно используйте решение предыдущего вызова в качестве инициализации, в противном случае просто сотрите предыдущее решение. Бесполезно для линейного решателя", "diap": null},
  {"id": 17, "use": true, "param": "n_iter_no_change", "type": "int", "default_value": null, "name": "Количество итераций без изменений", "info": "", "diap": [0]},
  {"id": 18, "use": true, "param": "tol", "type": "float", "default_value": 0.0001, "name": "Допуск по критериям остановки.", "info": "Допуск по критериям остановки.", "diap": [0]},
  {"id": 19, "use": true, "param": "ccp_alpha", "type": "float", "default_value": 0.0, "name": "Нарезка дерева", "info": "Параметр сложности, используемый для сокращения минимальной стоимости и сложности. Будет выбрано поддерево с наибольшей сложностью стоимости, меньшей, чем ccp_alpha. По умолчанию обрезка не выполняется.", "diap": [0]},
  {"id": 20, "use": true, "param": "validation_fraction", "type": "float", "default_value": 0.1, "name": "Валидационное разбиение", "info": "Доля обучающих данных, которые необходимо отложить в качестве набора проверки для ранней остановки. Значения должны находиться в диапазоне (0,0, 1,0). Используется только в том случае, если для параметра n_iter_no_change установлено целое число.", "diap": [0, 1]}
]